---
title: "Getting Started with surveydatar"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Getting Started with surveydatar}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>",
  eval = TRUE
)
library(surveydatar)
library(dplyr)
```

## Introduction

The surveydatar package provides a comprehensive toolkit for processing and analyzing survey data for market research in R. Survey data presents unique challenges: complex metadata, multiple question types, bases that vary by question, weighting, and the need to maintain the relationship between data and its documentation throughout the analysis pipeline.

This package addresses these challenges through:

-   **Integrated metadata management** via the `dpdict` (data processing dictionary)
-   **Automatic question grouping** and type detection
-   **Standardisation tools** for variable names and labels
-   **The `survey_data` object** that keeps data and metadata synchronized
-   **Validation functions** to ensure data integrity
-   **Weighting** functions for weighting survey data
-   **Flexible analysis** with the `tab()` function as supporting functions for flexible and fast cross-tabulations and significance testing

## Core Concepts

### The survey_data Object

At the heart of surveydatar is the `survey_data` S3 object. Think of it as a container that bundles your survey data with its complete metadata, ensuring they stay synchronized through all transformations.

```{r survey_data_object}
library(surveydatar)

# Load some example survey data
raw_data <- get_minimal_labelled_test_dat()

# Create a survey_data object - metadata is inferred automatically
survey_obj <- create_survey_data(raw_data)

# The object contains two components:
names(survey_obj)
#> [1] "dat"    "dpdict"

# Check object type and validity
is.survey_data(survey_obj)
#> [1] TRUE

validate_survey_data(survey_obj)
#> [1] TRUE
```

The `survey_data` object supports standard data manipulation while maintaining metadata integrity:

```{r preserving_structure}
# These operations preserve the survey_data structure through surveydatar's S3 methods
filtered <- filter(survey_obj, uid > 50)
selected <- select(survey_obj, uid, csat, nps_response)
with_new_var <- mutate(survey_obj, 
                       high_satisfaction = realiselabelled_vec(csat >= 4, 
                       variable_label = "High Satisfaction Flag"))
```

### The Metadata Dictionary (dpdict)

The `dpdict` is a data frame where each row describes a variable in your survey.

```{r basic_dpdict}
# Create a basic dpdict
dpdict <- create_dict(raw_data)
head(dpdict, 3)
```

Key columns in the dpdict include:

-   **Tracking columns**: `old_variable_names`, `old_variable_labels`, `old_value_labels`
-   **Current metadata**: `variable_names`, `variable_labels`, `value_labels`
-   **Question structure**: `question_group`, `questiontype`
-   **Display helper**: `question_suffix` (used by label_mode in tab/export)
-   **User-defined organization**: `question_alias`, `question_description`, `question_folder`, `alias_with_suffix` (for custom labelling/organization, not currently integrated with tab/export functions)
-   **Type indicators**: `variable_class`, `singlevariablequestion`, `multiresponse`

## Getting Started: Viewing Your Data

### Initial Data Exploration

Before processing, understand your data structure using `datamap()`:

```{r datamap}
# Load a more complex example dataset
survey_data <- get_big_test_dat(100)

# View an SPSS-style variable listing
dm <- datamap(survey_data, view_or_return = "return")
```

For `survey_data` objects, `datamap()` includes additional metadata:

```{r datamap_with_metadata}
survey_obj <- create_survey_data(survey_data)
dm_enhanced <- datamap(survey_obj, view_or_return = "return")
# Now includes question type, alias with suffix, etc.
```

### Question-Level View

See your data organized by question groups rather than individual variables:

```{r question_view}
# Get question-level summary
q_summary <- datamap_questions(survey_obj, view_or_return = "return")
```

## Creating and Enriching Metadata

### Starting Simple

For basic metadata capture and editing:

```{r starting_simple}
# Create an editable dpdict
raw_data <- get_minimal_labelled_test_dat()
basic_dpdict <- create_dict(raw_data, prefill = TRUE)

# Modify as needed
basic_dpdict$variable_labels[1] <- "Unique Identifier"
basic_dpdict$variable_names[2] <- "satisfaction_score"

# Apply changes back to data
updated_data <- update_dat_from_dpdict(raw_data, basic_dpdict)
```

### Automatic Metadata Inference

For a complete metadata setup with automatic inference:

```{r inference}
# This does everything: separators, grouping, type detection
survey_obj <- create_survey_data(get_big_test_dat(50))

# Or create dpdict with full metadata separately
full_dpdict <- create_dict_with_metadata(get_big_test_dat(50))
```

## Handling Separators

Survey software often produces inconsistent separator patterns across *variable names* and *variable labels*. In `surveydatar`, separators matter because several metadata operations assume that your data follows a consistent structure:

- Variable names for repeated items typically follow a `stem{var_name_sep}suffix` pattern (e.g. `Q1_1`, `Q1_2`).
- Variable labels are typically hierarchical and use separators to distinguish the question “stem” from the unique “suffix” within a question group (e.g. `Q1: Question text - Statement 1`).

These assumptions feed directly into `dpdict`-based workflows (especially `update_dict_with_metadata()`), including question grouping and suffix extraction. In practice: **standardise separators early (right after import), and keep them stable once you start editing a `dpdict`.**

```{r separators}
# Start with a dataset that has a consistent label prefix convention
messy_data <- get_big_test_dat_with_prefixes()

# Simulate a realistic issue:
# after import / merges / manual edits, a subset of variables use a different separator
# in their variable names and/or their label structure.
idx <- grep("_[0-9]+$", names(messy_data))
names(messy_data)[idx[1:2]] <- sub("_(\\d+)$", ".\\1", names(messy_data)[idx[1:2]])

# Prefix separator inconsistency (e.g. "Q1: ..." vs "Q1. ...")
attr(messy_data[[idx[1]]], "label") <- sub(": ", ". ", attr(messy_data[[idx[1]]], "label", exact = TRUE), fixed = TRUE)

# Statement separator inconsistency (e.g. "... - statement" vs "... | statement")
attr(messy_data[[idx[2]]], "label") <- sub(" - ", " | ", attr(messy_data[[idx[2]]], "label", exact = TRUE), fixed = TRUE)

# Analyze current separator patterns (and optionally print issues)
sep_analysis <- check_seps(messy_data, verbose = TRUE)
sep_analysis$separators
sep_analysis$consistency

# Recommended workflow: choose a separator scheme once, standardise, and carry it into dpdict work
seps_to_use <- list(var_name_sep = "_", prefix_sep = ": ", statement_sep = " - ")
standardised <- standardise_survey_separators(messy_data, seps_to_use = seps_to_use)
dat_std <- standardised$dat
dpdict_std <- standardised$dpdict

# `dpdict` keeps a record of the separator scheme used (useful for reproducibility)
attr(dpdict_std, "sep_patterns")

# If you want a simple audit of what would change, `get_updated_seps()` returns a mapping:
standardization_map <- get_updated_seps(messy_data, sep_analysis, seps_to_use = seps_to_use)
head(standardization_map[, c("old_variable_names", "new_variable_names",
                             "old_variable_labels", "new_variable_labels")], 3)
```

## Automatic Question Grouping

One of surveydatar's most powerful features is automatic detection of question groups. This is handled by `update_dict_with_metadata()`:

### How Question Grouping Works

The package uses `split_into_question_groups()` internally to:

1.  **Initialize groups** based on variable name prefixes (e.g., Q1_1, Q1_2 → group "Q1_a")
2.  **Split groups** when it detects:
    -   Change in variable class (`splitbyclass`)
    -   Different number of value labels (`splitbynumlabelledvalues`)
    -   Different actual label values (`splitbylabelvalues`) - note: disabled by default for performance
    -   Non-contiguous variables (`splitbynoncontiguous`)\
    -   Different common labels (`splitbycommonlabel`)

```{r grouping}
# Basic usage with default settings
survey_obj <- create_survey_data(get_big_test_dat(100))
survey_obj <- update_dict_with_metadata(survey_obj)

# See the detected groups
unique(survey_obj$dpdict$question_group)

# Custom configuration for specific needs
config <- list(
  splitbyclass = TRUE,           # Split when variable type changes
  splitbycommonlabel = TRUE,     # Split when label pattern changes
  findlongest = FALSE,           # Use fast label parsing (vs. LCS algorithm)
  min_common_strings = 5         # For findlongest = TRUE
)

survey_obj_custom <- update_dict_with_metadata(
  survey_obj, 
  split_into_groups_config = config,
  noisy = 1  # Show progress
)
```

### Understanding Question Types

Question types stored in the dpdict are automatically determined based on variable characteristics:

```{r question_types}
# View the inferred question types
table(survey_obj$dpdict$questiontype)
#> categorical  multiresponse  numeric  text
#>         15            12        8     3
```

Question types include: 
- **numeric**: Single numeric variables 
- **categorical**: Categorical variables of any number of categories 
- **multiresponse**: Binary variables in the same group 
- **text**: Character variables 
- **date**: Date/time variables

## Working with Question Metadata

### Question-Level Operations

Create and edit question-level metadata:

```{r question_level_metadata}
# Get a question-level summary
questions_dict <- create_questions_dict(survey_obj, editfirst = FALSE)
head(questions_dict)

# Manually update aliases
questions_dict$question_alias[1] <- "brand_awareness"
questions_dict$question_folder[1] <- "Marketing"

# Apply changes back
survey_obj <- update_aliases(survey_obj, questions_dict)
```

**Note:** These metadata fields (`question_alias`, `question_description`, `question_folder`, `alias_with_suffix`) are maintained for user-defined organization and custom labelling workflows. They are not currently integrated with `tab()`, `tab_to_reactable()`, or `tab_to_flourish()`. For controlling labels in tab output, use the `label_mode` parameter which leverages `question_suffix` and variable labels.

### Unique Suffixes

The package automatically determines the unique part of each variable label within its group:

```{r unique_suffixes}
# This happens automatically in update_dict_with_metadata
# but you can also call it directly
suffixes <- get_unique_suffixes(
  survey_obj$dpdict,
  seps_priority = c(" - ", ": ", " ")
)

# Results in clean suffixes like "Very satisfied", "Satisfied", etc.
# instead of full repeated question text
```

## Data Processing Tasks

### Converting Variable Types

Ensure variables have appropriate types and labels:

```{r converting_variables}
# Convert string variables to labelled factors where appropriate
survey_obj$dat <- realiselabelled(
  survey_obj$dat,
  max_labels = 20,  # Don't convert if too many unique values
  MRpositivelabel = "Selected",
  MRnegativelabel = "Not selected"
)
```

### Collapsing Wide Routed Questions

Some survey exports store routed versions of the same question in multiple columns (wide format). For example, a satisfaction question asked about a respondent's allocated concept might appear as `satisfaction_A`, `satisfaction_B`, `satisfaction_C`, with only one populated per respondent.

`collapse_wide_question()` collapses these into a single variable based on a reference variable (e.g. the concept allocation).

```{r collapse_wide_question_example}
wide_dat <- data.frame(
  id = 1:6,
  concept = c("A", "B", "A", "C", "B", "C"),
  satisfaction_A = c(5, NA, 4, NA, NA, NA),
  satisfaction_B = c(NA, 3, NA, NA, 2, NA),
  satisfaction_C = c(NA, NA, NA, 4, NA, 5)
)

wide_survey <- create_survey_data(wide_dat)

collapsed <- collapse_wide_question(
  wide_survey,
  vars_to_collapse = c("satisfaction_A", "satisfaction_B", "satisfaction_C"),
  collapse_on = "concept"
)

# The result contains a single satisfaction variable (and removes the wide inputs)
names(collapsed$dat)
```

### Preparing Data for SPSS Export

When exporting to SPSS via `haven::write_sav()`, it is often helpful to ensure labelled integer variables are stored as doubles. This can avoid type inconsistencies introduced during processing (for example, creating new labelled variables).

```{r spss_export_prep}
# Convert labelled integer columns to double (preserving labels/attributes)
survey_obj <- convert_integers_to_double(survey_obj)

# Additional export cleanup (names, labels, attributes)
export_data <- fix_for_spss_export(survey_obj$dat)

# Write a .sav file (example path)
# haven::write_sav(export_data, path = tempfile(fileext = ".sav"))
```

### Handling Multiresponse Questions

Process "select all that apply" questions correctly:

```{r multiresponse}
# Convert NAs to 0s only where at least one option was selected
survey_obj <- conditionally_replace_NAs_in_multiresponse(
  survey_obj,
  newvalue = 0,
  newlabel = "Not selected"
)
```

### Adding Derived Variables

Create new variables while preserving metadata:

```{r derived_variables}
# Add calculated variables with labels
survey_obj <- survey_obj %>%
  dplyr::mutate(
    # Create satisfaction groups using actual variable from test data
    satgroup = realiselabelled_vec(
      dplyr::case_when(
        labelledordinal <= 2 ~ "Dissatisfied",
        labelledordinal == 3 ~ "Neutral", 
        labelledordinal >= 4 ~ "Satisfied"
      ),
      variable_label = "Satisfaction Group"
    ),
    # Calculate average score using actual variables from test data
    avgscore = realiselabelled_vec(
      (labelledmultiordinal_1 + labelledmultiordinal_2) / 2,
      variable_label = "Average Multi-Ordinal Score"
    )
  )
```

## Validation and Quality Checks

Ensure data integrity throughout processing:

```{r validation}
# Check that data and metadata align
validate_dat_dpdict_alignment(survey_obj$dat, survey_obj$dpdict)

# Check for duplicate variable names or labels
validate_no_dpdict_duplicates(survey_obj$dpdict)

# Validate variable naming patterns
validate_variable_names(names(survey_obj$dat))

# Comprehensive validation
validate_survey_data(survey_obj)
```

## Quick Analysis with tab()

The `tab()` function provides flexible cross-tabulation capabilities. It returns a `tab_cell_collection` object that can be manipulated with derive and layout operations before being materialized to a data frame:

```{r tab}
# First add a weight variable to our survey object
survey_obj <- survey_obj %>%
  dplyr::mutate(
    weight_var = runif(nrow(survey_obj$dat), 0.5, 2.0),
    age_numeric = sample(18:65, nrow(survey_obj$dat), replace = TRUE)
  )

# Simple frequency table
tab(survey_obj, labelledordinal)

# Cross-tabulation 
tab(survey_obj, labelledordinal, categoricalasfactor)

# With filters and weights  
tab(survey_obj, 
    labelledordinal * (age_numeric > 30), 
    labelledcategorical,
    weight = "weight_var")

# Mean calculation
tab(survey_obj, categoricalasfactor, labelledcategorical, 
    statistic = "mean", 
    values = "age_numeric")

# Chain operations on cell collections
tab(survey_obj, labelledordinal, categoricalasfactor) %>%
  derive(delta_vs("DE", "FR")) %>%
  hide_rows("Don't know") %>%
  as.data.frame()
```

The cell-based architecture enables powerful post-computation operations like adding derived columns, reshaping with `pivot_to_grid()`, and flexible filtering. For comprehensive tab() documentation including derive operations, pivot_to_grid(), and advanced layout manipulation, see the dedicated tab vignette.

## A Complete Example

Let's walk through processing a customer satisfaction survey:

```{r complete}
# 1. Import raw data
raw_data <- get_big_test_dat(200)
raw_data$nps <- sjlabelled::set_label(sample(0:10, nrow(raw_data), replace = TRUE),
                                      label = "Example NPS score (0-10)")

# 2. Create survey_data object with automatic metadata
survey <- create_survey_data(raw_data)

# 3. Check current state
datamap(survey, view_or_return = "return") %>% head()
check_seps(survey$dat)

# 4. Update metadata with custom settings
survey <- update_dict_with_metadata(
  survey,
  split_into_groups_config = list(
    splitbycommonlabel = TRUE,
    findlongest = FALSE
  ),
  noisy = 1
)

# 5. Process multiresponse questions
survey <- conditionally_replace_NAs_in_multiresponse(survey)

# 6. Add derived variables
survey <- survey %>%
  dplyr::mutate(
    nps_category = realiselabelled_vec(
      dplyr::case_when(
        nps <= 6 ~ "Detractor",
        nps <= 8 ~ "Passive",
        nps >= 9 ~ "Promoter"
      ),
      variable_label = "NPS Category"
    )
  )

# 7. Quick analysis
tab(survey, nps_category, labelledcategorical)

# 8. Export if needed
export_data <- fix_for_spss_export(convert_integers_to_double(survey$dat))
# haven::write_sav(export_data, path = tempfile(fileext = ".sav"))
```

## Weighting (brief)

For workflows that require weighting beyond simple calibration factors, `surveydatar` includes a unified weighting engine. The main entry point is `run_unified_weighting()`, which accepts one or more stages with constraint specifications (including optional tolerances via `%+-%`).

```{r weighting_brief, eval = FALSE}
# Minimal sketch of the API (example only)
result <- run_unified_weighting(
  raw_data = survey,
  stages = list(
    list(
      constraints = list(
        (gender == "Female") ~ 0.5 %+-% 0.02,
        (gender == "Male") ~ 0.5 %+-% 0.02
      ),
      tolerance = 0.02,
      alpha = 0
    )
  ),
  cap = 3,
  verbose = TRUE
)

# Weighted data and diagnostics are returned in a structured result
str(result)
```

## Conclusion

The surveydatar package streamlines survey data processing by:

-   **Maintaining synchronized metadata** through the survey_data object
-   **Automatically detecting structure** via intelligent question grouping
-   **Standardizing formats** while preserving original information
-   **Providing flexible analysis** through the tab() function
-   **Ensuring quality** with comprehensive validation tools

This structured approach reduces errors, improves reproducibility, and makes survey data analysis more efficient. The package handles the tedious aspects of survey data management, letting you focus on insights rather than data wrangling.

For more details on specific functions, see the package documentation. For advanced cross-tabulation features, see the tab vignette.
